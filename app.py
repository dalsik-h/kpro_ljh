import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler

from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score



plt.rc('font', family='Malgun Gothic')
plt.rcParams['axes.unicode_minus'] = False

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('./pip_dataset_pro.csv', index_col='date_time', parse_dates=True)

df.drop(['thj_vv_open_3'], axis=1, inplace=True)

# ë°ì´í„° ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df)

df_scaled = pd.DataFrame(df_scaled, columns=df.columns)

# êµ°ì§‘ ìˆ˜ ê²°ì •
inertia = []
K_range = range(1, 11)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(df_scaled)
    inertia.append(kmeans.inertia_)

plt.figure(figsize=(8, 4))
plt.plot(K_range, inertia, marker='o')
plt.xlabel('k (Number of Clusters)')
plt.ylabel('Inertia')
plt.title('Elbow Method to Determine Optimal k')
plt.grid()
plt.show()

# ì—˜ë³´ìš° methodë¡œ ì‹œê°í™” ê²°ê³¼ 3ë˜ëŠ” 4

# í´ëŸ¬ìŠ¤í„°ë§ ëŒ€ìƒì€ scaled_df (ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„°)

def evaluate_kmeans(X, k):
    model = KMeans(n_clusters=k, random_state=42, n_init=10)
    labels = model.fit_predict(X)
    
    silhouette = silhouette_score(X, labels)
    calinski = calinski_harabasz_score(X, labels)
    davies = davies_bouldin_score(X, labels)
    
    print(f"=== K = {k} ===")
    print(f"Silhouette Score       : {silhouette:.4f}")
    print(f"Calinski-Harabasz Index: {calinski:.2f}")
    print(f"Davies-Bouldin Index   : {davies:.4f}")
    print()

# k = 3ê³¼ 4 ëª¨ë‘ í‰ê°€
evaluate_kmeans(df_scaled, 3)
evaluate_kmeans(df_scaled, 4)

# k-means ì‹¤í–‰
optimal_k = 4  # elbowì—ì„œ í™•ì¸í•œ ê°’(3 ë˜ëŠ” 4) ì ìš©
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
clusters = kmeans.fit_predict(df_scaled)

# ê²°ê³¼ë¥¼ ì›ë³¸ì— ì¶”ê°€
df['cluster'] = clusters

# ê° êµ°ì§‘ì˜ í‰ê· ê°’ ë³´ê¸°
cluster_summary = df.groupby('cluster').mean()
print(cluster_summary)

# 2ì°¨ì› ì¶•ì†Œë¥¼ í†µí•œ ì‹œê°í™”
pca = PCA(n_components=2)
df_pca = pca.fit_transform(df_scaled)

plt.figure(figsize=(8, 6))
plt.scatter(df_pca[:, 0], df_pca[:, 1], c=clusters, cmap='tab10', alpha=0.7)
plt.xlabel('PCA 1')
plt.ylabel('PCA 2')
plt.title('KMeans Clustering Result (PCA 2D)')
plt.colorbar(label='Cluster')
plt.grid()
plt.show()

# t-sne ë¶„ì„

# t-SNE ëª¨ë¸ ìƒì„± ë° ë³€í™˜ (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŒ)
tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)
tsne_result = tsne.fit_transform(df_scaled)  # scaled_dfëŠ” í‘œì¤€í™”ëœ ë°ì´í„°

# t-SNE ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì €ì¥
df['tsne_1'] = tsne_result[:, 0]
df['tsne_2'] = tsne_result[:, 1]

# ì‹œê°í™”
plt.figure(figsize=(10, 6))
scatter = plt.scatter(df['tsne_1'], df['tsne_2'], c=df['cluster'], cmap='tab10', s=10, alpha=0.7)
plt.title("t-SNE Clustering Visualization")
plt.xlabel("t-SNE Dimension 1")
plt.ylabel("t-SNE Dimension 2")
plt.colorbar(scatter, label="Cluster")
plt.grid(True)
plt.show()

# í´ëŸ¬ìŠ¤í„°ë³„ ë°ì´í„° í†µê³„ì¹˜ ë¶„ì„

# í´ëŸ¬ìŠ¤í„° 0ë§Œ í•„í„°ë§
cluster_0 = df[df['cluster'] == 0]

# ì „ì²´ ì¤‘ ëª‡ ê°œì¸ì§€, ëª‡ í¼ì„¼íŠ¸ì¸ì§€ ê³„ì‚°
total_len = len(df)
cluster_0_len = len(cluster_0)
percentage = cluster_0_len / total_len * 100

# ë©”ì‹œì§€ ì¶œë ¥
message = (
    f"â–£ í´ëŸ¬ìŠ¤í„° '0'ì€ ì „ì²´ {total_len:,}ê°œ ì¤‘ {cluster_0_len:,}ê°œë¥¼ ì°¨ì§€í•©ë‹ˆë‹¤. ({percentage:.2f}%)<br>"
    f"  â˜ í´ëŸ¬ìŠ¤í„° 0 ìš”ì•½"
)
# ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì„ íƒ (ì˜ˆ: date_time ì œì™¸)
numeric_cols = df.select_dtypes(include='number').columns.drop('cluster')

# í‰ê· 
mean_values = cluster_0[numeric_cols].mean().to_frame(name='Mean')

# ìµœë¹ˆê°’ (modeëŠ” ì—¬ëŸ¬ ê°œì¼ ìˆ˜ ìˆì–´ ì²« ë²ˆì§¸ë§Œ ì‚¬ìš©)
mode_values = cluster_0[numeric_cols].mode().iloc[0].to_frame(name='Mode')

# ìµœì†Œ/ìµœëŒ€
min_values = cluster_0[numeric_cols].min().to_frame(name='Min')
max_values = cluster_0[numeric_cols].max().to_frame(name='Max')

# ë¶„ìœ„ìˆ˜
quantiles = cluster_0[numeric_cols].quantile([0.25, 0.5, 0.75])
quantiles.index = ['Q1 (25%)', 'Q2 (Median)', 'Q3 (75%)']
quantiles = quantiles.T

# ëª¨ë“  í†µê³„ ê²°í•©
summary = pd.concat([mean_values, mode_values, min_values, max_values, quantiles], axis=1)

# ì¶œë ¥
# print("ğŸ“Š í´ëŸ¬ìŠ¤í„° 0ì˜ í†µê³„ ìš”ì•½:\n")
# print(summary.round(2))  # ë³´ê¸° ì¢‹ê²Œ ë°˜ì˜¬ë¦¼
